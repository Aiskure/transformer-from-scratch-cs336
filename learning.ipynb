{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e7cb31",
   "metadata": {},
   "source": [
    "# 学习笔记\n",
    "\n",
    "## 1.BPE(Byte-Pair Encoding)\n",
    "\n",
    "(参考链接)[https://zhuanlan.zhihu.com/p/20877214508]\n",
    "\n",
    "---\n",
    "\n",
    "### 分词的三种主要方式\n",
    "1. 词级别分词\n",
    "- 最直观的方式,直接按照完整的词来切分\n",
    "- 优点:保留了完整的词义\n",
    "- 缺点:\n",
    "    - 词表太大,存储和计算成本高\n",
    "    - 无法处理生僻词或新词(OOV问题)\n",
    "    - 难以处理词形变化(如:play、playing、played)\n",
    "2. 字符级别分词\n",
    "- 将文本切分成单个字符\n",
    "- 优点:词表小,完全没有OOV问题\n",
    "- 缺点:\n",
    "    - 失去了词义信息\n",
    "    - 文本序列变得很长,增加处理难度\n",
    "3. 子词级别分词(Subword)\n",
    "- 介于词和字符之间的折中方案\n",
    "- 常用词保持完整,罕见词拆分成更小的单位\n",
    "- 主流算法包括BPE、WordPiece等\n",
    "- 优点:平衡了词表大小和语义表达能力\n",
    "\n",
    "### BPE算法原理\n",
    "\n",
    "BPE分为三步：初始化、预分词(pre-tokenization)和合并\n",
    "\n",
    "#### 1. 初始化\n",
    "\n",
    "我们会有一个初始词汇表，包含所有256个可能的字节值，因此初始大小为256\n",
    "\n",
    "#### 2. 预分词\n",
    "\n",
    "预分词就是统计文本中相邻字符出现的频率。\n",
    "\n",
    "- 理论上我们可以直接在原始字节序列上统计相邻自己对的出现频率并合并，但是这样每次就要遍历整个语料库，计算成本高。\n",
    "\n",
    "- 如果不加成本地跨文本合并字节，可能导致如\"dog.\"和\"dog!\"这样的词被完全无关的标记。\n",
    "\n",
    "| 阶段 | 处理结果 | 说明 |\n",
    "| --- | --- | --- |\n",
    "| **原始文本** | `Hello, world!` | 包含空格和标点。 |\n",
    "| **预分词** | `[\"Hello\", \",\", \"world\", \"!\"]` | **关键一步：** 按照空格和标点切开，确保标点符号不会和单词粘在一起。 |\n",
    "| **子词切分** | `[\"Hell\", \"##o\", \",\", \"world\", \"!\"]` | 在预分词的基础上，进一步拆分为模型词表里的最小单位（Token）。 |\n",
    "\n",
    "### 3. 合并\n",
    "\n",
    "以论文中的示例说明：假设语料包含以下文本：  \n",
    "```\n",
    "low low low low low  \n",
    "lower lower widest widest widest  \n",
    "newest newest newest newest newest newest  \n",
    "```\n",
    "\n",
    "并设定<|endoftext|>为特殊标记。  \n",
    "\n",
    "初始词汇表包括<|endoftext|>和全部256个字节。\n",
    "\n",
    "- 预分词采用空格分割，得到频次统计：low（5次）、lower（2次）、widest（3次）、newest（6次），可表示为字节元组的频数字典，如`{(b'l', b'o', b'w'): 5, ...}`。\n",
    "\n",
    "- 随后统计所有相邻字节对的频率：lo（7次）、ow（7次）、we（8次）、er（2次）、wi（3次）、id（3次）、de（3次）、es（9次）、st（9次）、ne（6次）、ew（6次）。\n",
    "\n",
    "- 其中（es）和（st）频率最高且相同，按字典序选择更大的（st）进行合并。于是，所有包含“st”的词如“widest”和“newest”中的“s”和“t”被合并为新标记“st”。\n",
    "\n",
    "- 第二轮中，“e”与“st”组合出现9次，成为最高频对，合并为“est”。继续此过程，后续合并依次为“ow”、“low”、“west”、“ne”等。若仅执行6次合并，最终新增标记为['s t', 'e st', 'o w', 'l ow', 'w est', 'n e']。  \n",
    "\n",
    "- [<|endoftext|>, [...256 BYTE CHARS], st, est, ow, low, west, ne]  \n",
    "\n",
    "此时，“newest”将被切分为[ne, west]两个标记。这一机制在保持对未知词处理能力的同时，有效压缩了序列长度，提升了模型效率。  \n",
    "\n",
    "同时我们一直重复合并过程直到词表达到一个预设的值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b9f78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
      "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
      "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n",
      "<|endoftext|>\n",
      "Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\n",
      "One day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/aiskure/Desktop/transformer-from-scratch-cs336/data/TinyStories-train.txt', 'r') as f:\n",
    "    print(f.read(1000)) # 读取前1000个字符"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
